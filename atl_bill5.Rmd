---
title: "anti-trans legislation exploratory"
author: "DAAAAMN OER group"
date: "2023-07-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
This is a workbook for the exploratory data analysis in R on the 4 anti-trans bills.

Before we did the analysis we had to do some data cleaning. Here is an example of some text
___
Be it enacted by the Legislature of the State of Arizona:

Section 1. Title 15, chapter 5, article 1, Arizona Revised Statutes, is amended by adding section 15-509, to read:

15-509. Pronouns; biological sex; parental permission; prohibition; policies

A. AN EMPLOYEE OR INDEPENDENT CONTRACTOR OF A SCHOOL DISTRICT OR CHARTER SCHOOL MAY NOT KNOWINGLY ADDRESS, IDENTIFY OR REFER TO A STUDENT WHO IS UNDER EIGHTEEN YEARS OF AGE BY EITHER OF THE FOLLOWING UNLESS THE SCHOOL DISTRICT OR CHARTER SCHOOL RECEIVES WRITTEN PERMISSION FROM THE STUDENT'S PARENT:

1. A PRONOUN THAT DIFFERS FROM THE PRONOUN THAT ALIGNS WITH THE STUDENT'S BIOLOGICAL SEX.

2. A FIRST NAME OTHER THAN THE FIRST OR MIDDLE NAME THAT IS LISTED ON THE STUDENT'S OFFICIAL SCHOOL RECORDS, EXCEPT THAT AN EMPLOYEE OR INDEPENDENT CONTRACTOR MAY ADDRESS, IDENTIFY OR REFER TO A STUDENT BY A NICKNAME THAT IS COMMONLY ASSOCIATED WITH THE STUDENT'S NAME OF RECORD.

B. A SCHOOL DISTRICT OR CHARTER SCHOOL MAY NOT REQUIRE AN EMPLOYEE OR INDEPENDENT CONTRACTOR TO ADDRESS, IDENTIFY OR REFER TO A PERSON BY A PRONOUN THAT DIFFERS FROM THE PRONOUN THAT ALIGNS WITH THE PERSON'S BIOLOGICAL SEX IF DOING SO IS CONTRARY TO THE EMPLOYEE'S OR INDEPENDENT CONTRACTOR'S RELIGIOUS OR MORAL CONVICTIONS.

C. EACH SCHOOL DISTRICT GOVERNING BOARD AND CHARTER SCHOOL GOVERNING BODY SHALL ADOPT POLICIES TO IMPLEMENT THIS SECTION.

D. THIS SECTION DOES NOT PROHIBIT ANY PERSON DESCRIBED IN SUBSECTION A OF THIS SECTION FROM DISCUSSING MATTERS OF PUBLIC CONCERN OUTSIDE THE CONTEXT OF THE PERSON'S OFFICIAL DUTIES. 
___


The initial section is metadata which describes the bill and how and where it has been amended. Keeping track of the bill revisions may be interesting, but here we are interested in the document as it stands. In addition, the addendum in this bill is a duplication of lines below.  Therefore we remove the following:
"Be it enacted by the Legislature of the State of Arizona:

Section 1. Title 15, chapter 5, article 1, Arizona Revised Statutes, is amended by adding section 15-509, to read:

15-509. Pronouns; biological sex; parental permission; prohibition; policies"

We also remove the "1. " "A. " etc before each line. We discussed how the numbering of the itemization is less important to us than the content within. Some of the documents also have bill numbers, line numbers, page numbers, or time stamps, which we remove for similar reasons.

In some legislation that reques changes to multiple sections, occassionally preamble is repeated at the start to each section. See the examples below from Florida:
___
  147         Section 5. Section 456.52, Florida Statutes, is created to
  148  read:
  149         456.52
___

___
CS/CS/HB 1421 2023
CODING: Words stricken are deletions; words underlined are additions.
hb1421-02-c2
Page 10 of 10
F L O R I D A H O U S E O F R E P R E S E N T A T I V E S
___
We pulled this in our manual cleaning of the test data sets, but may not have to be pulled.
Same with numbers, (_), and "Section 5." type headers. It may be okay to leave them in if it is a broader analysis.
"s." and "ss." could be pulled as they are short for section(s).
Sometimes line numbers have 1 space after, sometimes 2


```{r}
library(readxl)
bills <- read_excel("4-bill-test.xlsx")
View(bills)
template_leg <- read_excel("template legislation.xlsx")
View(template_leg)
probills <- read_excel("pro-LGBTQbills-test.xlsx")
View(probills)
```

## Clean data

We need some tools for text cleaning
```{r}
#install.packages("stopwords")
library(stringr)
library(stopwords)
```
Have a look at the text imported

```{r}
# we are going to do the fifth anti-trans bill - the one on healthcare that the judge commented on 
i = 5
ltext<-bills$text[i]
ltext
```


The syntax for removal is: 'str_replace_all(string, pattern, replacement)'. In the RStudio IDE, you can click on the function word and hit F1, and it brings up the help documentation which has some nice examples.

We will go ahead and make several substitutions and replacements. 

### Removing line breaks
```{r}
# Replace all instances of "\n" (newline) with a space - use escape characters
# You have to add a space otherwise words will run together
ltext <- str_replace_all(ltext, "\\\n", " ")
```

### Completely delete a phrase or line
``` {r}
# "\r" is carriage return
ltext <- str_replace_all(ltext, "\\\r", " ")

# We are going to remove "." and "," next. There are a few reasons for this. I see U.S. will be US and there are some places where the end "." is interfering with removing/matching some words for replacement and removal.

# If we were looking at word/sentence relationships, we may have wanted to keep periods and question marks first to define sentences before breaking up into words. 
ltext <- str_replace_all(ltext, "\\.", "")
ltext <- str_replace_all(ltext, ",", " ")
ltext <- str_replace_all(ltext, "'", "")
ltext <- str_replace_all(ltext, "’", "")
ltext <- str_replace_all(ltext, "‘", "")
ltext <- str_replace_all(ltext, "“", "")
ltext <- str_replace_all(ltext, "”", "")
ltext <- str_replace_all(ltext, '\\\"', ' ')
ltext <- str_replace_all(ltext, "-", "")
ltext <- str_replace_all(ltext, ":", " ")
ltext <- str_replace_all(ltext, "/", "")
ltext <- str_replace_all(ltext, "\\\\", "") #remove \
ltext <- str_replace_all(ltext, ";", " ")
ltext <- str_replace_all(ltext, "§", " ")
ltext <- str_replace_all(ltext, " · ", " ")

#ltext <- str_replace_all(ltext, "\\?", "")

# We also have () and [] to be removed
ltext <- str_replace_all(ltext, "\\(|\\)|\\[|\\]", "")

#lets check progress
#ltext

```

### Delete certain phrases

``` {r}
# This text tends to have a 1. and a. and (a) and (b). We already eliminated parentheses and periods, so now we are going to eliminate all single letter words and numbers.  We are intentionally not removing all numbers. There are several references to k12 or under 18 so we want to maintain these.
ltext <- str_replace_all(ltext, " [a-zA-Z0-9] ", " ")

# We now want to make sure that our words will be recognized as the same when we construct relationships, so we have to converting everything to lowercase.
ltext <- str_to_lower(ltext)
ltext
```

Finally, we clean up redundant spaces
``` {r}
# Replace multiple spaces with one space
# s+ means 1 or more spaces.  \\ are escape characters
ltext <- str_replace_all(ltext, "\\s+", " ")

# Delete spaces at the start and end of our text
ltext<-trimws(ltext, "both")
```

Check to make sure there isn't anything else that needs removing, such as numbers.

``` {r}
ltext
```


### Cleaning for an effective text analysis

Are there any words that make sense to eliminate in our analysis?

``` {r}
# Identify stop words
# stopwords gives us a list of such words
# otherwise we could manually define these, or even add to this list
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
ltext <- str_replace_all(ltext, stopwords_regex, '')
```


### Get a vector of words
We now have one list of words in a 1x1 matrix. We need to convert that to a vector with one word in each slot.

``` {r}
# Remember that strsplit returns a list of lists
ltext_ls<- str_split(ltext, " ")
```

I recommend viewing 'ltext_ls' to get a sense of how the list looks.  

I am saving this as a vector and exporting it to csv for later independent use. You can also structure your word vector data so that each row in "bills" is duplicated and then a word vector row. So if my bill had 4 words, I can have 4 rows for bill1 that have the same descriptor data (e.g. Healthcare) and but under the "words" column, rown 1 has the first word, row 2 has the second word, etc. That is probably the best way to structure the data, but it makes it harder to visualize the data when you have over 400 words like bill 1 actually has.

``` {r}
# Grab just the vector
ltext_vec<- ltext_ls[[1]]

# convert to data frame
ltext_vec<-as.data.frame(ltext_vec)
colnames(ltext_vec) <- c("words")

#write a csv of the cleaned words.  That way you can just do the next section without running the cleaning parts.
billname = paste0("bill_",i)
write.csv(ltext_vec, file = billname, row.names = FALSE)
```

## Visualizing the word vector output

### Summary of the data
```{r}
library(dplyr)
# Get a sense for the data through a table of word counts

# you will need a read command if you are just picking up from the cleaned text
ltext_df<-read.csv(file = billname)

#how many words are there? This may come up later
n_words <- dim(ltext_vec)[1]

# Use dplyr to automatically count the words that exist. This creates a table (in a dataframe structure) in which you have the list of unique words and an absolute frequency count next to each word.
ltext_counts <- ltext_df %>% count(words)

#relative freq
ltext_counts$relf <- ltext_counts$n / n_words
View(ltext_counts)

# use dim() to tell me how big the matrix is
print(dim(ltext_counts))

```

The first number is rows (67) and the second is columns (3). This means that our word vector contains 67 distinct words & 3 columns - the word, the absolute frequency or count, and the relative frequency or probability of occurance. 

Some methods of visualization, like the base plotting function in R, use this form of the data.


### Base plot in R
```{r}
# This is the base plotting function in R
barplot(height=ltext_counts$n, names=ltext_counts$words)

# Great reference
# https://r-graph-gallery.com/208-basic-barplot.html
```

This plot is illegible. Because it has 226 words. We can look instead at just the 20 most frequently used words.

### Top 20

```{r}
#This will order in descending order
counts_ordered <- ltext_counts %>% arrange(desc(n))
View(counts_ordered)

#This will extract the top 20 for visualization purposes
top20 <-  head(counts_ordered, 20)
top20
```


```{r}
# Same but top 20
barplot(height=top20$n, names=top20$words)

```

This is much better, but you cannot read the words, so we will have the words tilted for better readability
```{r}
# las 2 will make vertical labels
# col will make it a little less boring in color
barplot(height=top20$n, names=top20$words, las = 2, col=rgb(0.2,0.4,0.6,0.6) )

# Great reference for options
# https://r-graph-gallery.com/209-the-options-of-barplot.html
```

### Plot in ggplot2

ggplot2 can look prettier :)
```{r}
library(ggplot2)
# ggplot2 version
# help guide: https://r-graph-gallery.com/218-basic-barplots-with-ggplot2.html
ggplot(top20, aes(x=words, y=n)) + 
  geom_bar(stat = "identity")

```

again the figure would be more easily read if the text was vertical
```{r}
ggplot(top20, aes(x=words, y=n)) + 
  geom_bar(stat = "identity", color=rgb(0.1,0.4,0.5,0.7), fill=rgb(0.1,0.4,0.5,0.7)) +
# Rotate x-axis text to make labels vertical
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = NULL)  # or xlab("")

```

Reorder from biggest to smallest
```{r}
# This pulls the words as ordered
ordered.words <- top20 %>%
  arrange(desc(n)) %>%
  pull(words)

# This will help ggplot interpret the words as factors, and in particular, factors with a particular order.
top20$words <- ordered(top20$words, levels = ordered.words)

top20 %>%
ggplot(aes(x=words, y=n)) + 
  geom_bar(stat = "identity", color=rgb(0.1,0.4,0.5,0.7), fill=rgb(0.1,0.4,0.5,0.7)) +
# Rotate x-axis text to make labels vertical
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = NULL)  # or xlab("")
```


